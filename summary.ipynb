{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## einops 里的常用的操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 32])\n",
      "tensor([1, 1, 1, 2, 2, 2, 3, 3, 3])\n",
      "tensor([1, 2, 3, 1, 2, 3, 1, 2, 3])\n",
      "tensor([[1, 1, 1, 2, 2, 2],\n",
      "        [1, 1, 1, 2, 2, 2],\n",
      "        [1, 1, 1, 2, 2, 2],\n",
      "        [3, 3, 3, 4, 4, 4],\n",
      "        [3, 3, 3, 4, 4, 4],\n",
      "        [3, 3, 3, 4, 4, 4]])\n",
      "tensor([[1, 2, 3],\n",
      "        [1, 2, 3]])\n",
      "torch.Size([1, 2, 3, 6])\n",
      "tensor([ 0.0557, -2.0250])\n"
     ]
    }
   ],
   "source": [
    "# einops 里的常用的操作\n",
    "from einops import rearrange,repeat,reduce,einsum\n",
    "from einops.layers.torch import Rearrange,Reduce\n",
    "import torch\n",
    "\n",
    "\"\"\" \n",
    "1. rearrange\n",
    "重新排列张量的维度，支持维度重排、合并、拆分等操作\n",
    "output = rearrange ( tensor , pattern , ** axes_lengths )\n",
    "param:\n",
    "    tensor ：输入张量。 \n",
    "    pattern ：描述维度变换的字符串。 \n",
    "    axes_lengths ：可选参数，用于指定新维度的长度。\n",
    "\"\"\"\n",
    "# 将高度和宽度合并为空间维度\n",
    "x = torch.randn(3, 32, 32) # [C, H, W]\n",
    "y = rearrange(x, 'c h w -> h w c') # [H, W, C]\n",
    "\n",
    "# 将通道维度拆分为 [C1, C2]\n",
    "x = torch.randn(32,64,14,14)\n",
    "y = rearrange(x,'b (c1 c2) h w -> b c1 c2 h w',c1 = 8)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "2. reduce\n",
    "reduce 的核心功能是在指定维度上进行聚合操作，\n",
    "支持以下聚合操作：\n",
    "    求和 （ \"sum\" ） 均值 （ \"mean\" ） 最大值 （ \"max\" ） 最小值 （ \"min\" ） 乘积 （ \"prod\" ）\n",
    "output = reduce ( tensor , pattern , reduction , ** axes_lengths )\n",
    "param:\n",
    "    tensor ：输入张量。 \n",
    "    pattern ：描述维度变换和聚合的字符串。 \n",
    "    reduction ：聚合操作类型（如 \"sum\" 、 \"mean\" 等）。 \n",
    "    axes_lengths ：可选参数，用于指定新维度的长度。\n",
    "\"\"\"\n",
    "# 简单聚合，对通道维度平均\n",
    "x = torch.randn(3, 32, 32)\n",
    "y = reduce(x, \"b c h -> b c\", reduction=\"mean\")\n",
    "print(y.shape)\n",
    "# 求和聚合以及最大最小值等都是一样的    \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "3. repeat\n",
    "repeat 的核心功能是在指定维度上重复张量的数据\n",
    "output = repeat ( tensor , pattern , ** axes_lengths )\n",
    "param:\n",
    "    tensor ：输入张量。 \n",
    "    pattern ：描述维度变换和重复的字符串。 \n",
    "    axes_lengths ：可选参数，用于指定新维度的长度。\n",
    "ps!!! einops 的模式语法要求每个维度名称必须是唯一的\n",
    "\"\"\"\n",
    "# 在单个维度上重复\n",
    "x = torch.tensor([1,2,3]) # shape:[3]\n",
    "y = repeat(x,'b -> (b rep)', rep = 3)\n",
    "print(y) # tensor([1, 1, 1, 2, 2, 2, 3, 3, 3])\n",
    "\n",
    "# 在单个维度上重复\n",
    "x = torch.tensor([1,2,3])\n",
    "y = repeat(x,'b -> (rep b)', rep = 3)\n",
    "print(y) # tensor([1, 2, 3, 1, 2, 3, 1, 2, 3])\n",
    "\n",
    "# 在多个维度上重复\n",
    "x = torch.tensor([[1,2],[3,4]]) # shape:[2,2]\n",
    "y = repeat(x,'b c -> (b rep) (c rep1)', rep = 3,rep1 = 3) # einops 的模式语法要求每个维度名称必须是唯一的\n",
    "print(y)\n",
    "\n",
    "# 广播式重复，添加一个新维度并重复\n",
    "x = torch.tensor([1,2,3]) # shape: [3]\n",
    "y = repeat(x, 'b -> c b' ,c = 2)\n",
    "print(y) # tensor([[1, 2, 3],[1, 2, 3]])\n",
    "\n",
    "\"\"\"\n",
    "4. einsum\n",
    "einsum(爱因斯坦求和约定）是一种强大的工具，用于表示和执行张量之间的复杂操作，如矩阵乘法、点积、外积、转置等。它的核心思想是通过下标符号来描述张量之间的操作，而不需要显式地编写循环或调用特定的函数。\n",
    "output = einsum (* tensors, equation  )\n",
    "param: \n",
    "    equation ：描述操作的字符串，使用下标符号表示输入和输出张量的维度。 \n",
    "    *tensors ：参与操作的张量。   \n",
    "隐含规则！！！所有未出现在输出的维度会被求和\n",
    "\"\"\"\n",
    "# 矩阵乘法\n",
    "A = torch.randn(1, 2, 3, 4)  # Shape: [1, 2, 3, 4]\n",
    "B = torch.randn(1, 2, 4, 6)  # Shape: [1, 2, 4, 6]\n",
    "C = einsum(A,B,\"b s i j, b s j k -> b s i k\")\n",
    "print(C.shape)  # 输出: [1, 2, 3, 6]\n",
    "\n",
    "# 点积\n",
    "A = torch.randn(2,3)\n",
    "B = torch.randn(2,3)\n",
    "C = einsum(A,B,'a b,a b -> a') # A和B每一行的对应位置做乘法求和\n",
    "print(C)\n",
    "\n",
    "\"\"\"\n",
    "5. torch中的tensor和numpy的转换\n",
    "param:\n",
    "    detach(): 是 PyTorch 中 torch.Tensor 的一个方法，用于从计算图中分离张量，生成一个新的张量。这个新张量不再追踪梯度，也不会参与反向传播。\n",
    "    cpu(): 是 PyTorch 中 torch.Tensor 的一个方法，用于将张量从 GPU（或其他设备，如 CUDA）移动到 CPU 内存。\n",
    "\"\"\"\n",
    "# tensor -> numpy\n",
    "tensor = torch.randn(2,3,4)\n",
    "numpy_array = tensor.detach().cpu().numpy()\n",
    "\n",
    "# numpy -> tensor\n",
    "tensor = torch.as_tensor(numpy_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch 里的常用操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 张量操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 3, 5])\n",
      "torch.Size([1, 2, 3, 5])\n",
      "torch.Size([3, 2])\n",
      "torch.Size([1, 3, 1, 2])\n",
      "torch.Size([3, 2, 4])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\"\"\"1. 创建张量\"\"\"\n",
    "x = torch.randn(3,4) # 正态分布随机数\n",
    "x = torch.zeros(3,4) # 创建全零张量\n",
    "y = torch.randn_like(x,dtype=torch.float16) # 创建和x形状一样的正态分布随机数\n",
    "y = torch.zeros_like(x) # 创建和x形状一样的全0张量\n",
    "x = x.to(torch.float32)\n",
    "\n",
    "\"\"\"2. 数学运算\"\"\"\n",
    "# 执行广义上的张量乘法, 对于高维张量, 对最后两个维度进行矩阵乘法\n",
    "x = torch.randn(1,2,3,4)\n",
    "y = torch.randn(1,2,4,5)\n",
    "\n",
    "c1 = x@y # 矩阵乘法\n",
    "print(c1.shape) # torch.Size([1, 2, 3, 5])\n",
    "\n",
    "c2 = torch.matmul(x,y) # 和@操作等价\n",
    "print(c2.shape)\n",
    "\n",
    "\"\"\"\n",
    "广播机制（Broadcasting）允许在不同形状的张量（或数组）之间进行逐元素操作，而无需显式地扩展它们的形状。\n",
    "广播机制的核心思想是:\n",
    "    自动扩展较小张量的形状，使其与较大张量的形状兼容 ，从而支持逐元素操作。\n",
    "\"\"\"\n",
    "# 向量与标量的加法\n",
    "x = torch.tensor([1,2,3])\n",
    "y = 2\n",
    "c = x + y   # 应用广播机制将 y 扩展为[2,2,2]\n",
    "# 矩阵与向量的加法\n",
    "x = torch.tensor([[1,2,3],[4,5,6]])\n",
    "y = torch.tensor([1,2,3])\n",
    "c = x + y   # 应用广播机制将 y 扩展为 [[1,2,3],[1,2,3]]\n",
    "\n",
    "# squeeze() 和 unsqueeze()\n",
    "\"\"\"\n",
    "torch.squeeze(input, dim=None)\n",
    "param:\n",
    "    input : 输入张量。 \n",
    "    dim : 可选参数，指定要删除的维度。如果未指定，则删除所有大小为 1 的维度。\n",
    "\"\"\"\n",
    "x = torch.randn(1,3,1,2)\n",
    "y = torch.squeeze(x)    # 未指定维度，删除所有大小为1的维度\n",
    "print(y.shape)          # (3,2)\n",
    "\n",
    "y = torch.squeeze(x,dim =1) # 指定维度大小不为1，不执行删除维度的操作\n",
    "print(y.shape)              # (1,3,1,2)\n",
    "\"\"\"\n",
    "unsqueeze() 用于 在指定位置添加一个大小为 1 的维度 ，从而扩展张量的形状。\n",
    "torch.unsqueeze(input, dim)\n",
    "param:\n",
    "    input : 输入张量。 \n",
    "    dim : 指定要添加维度的位置（从 0 开始）\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# stack() 和 cat()\n",
    "# 创建批次\n",
    "sample1 = torch.randn(3, 4)  # 形状: (3, 4)\n",
    "sample2 = torch.randn(3, 4)  # 形状: (3, 4)\n",
    "batch1 = torch.stack([sample1, sample2], dim=0)  # 形状: (2, 3, 4)\n",
    "batch2 = torch.stack([sample1,sample2], dim=0)   # 形状: (6,4)\n",
    "batch3 = torch.stack([sample1, sample2], dim=1)  # 形状: (3, 2, 4)\n",
    "print(batch3.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 总结\n",
    "\n",
    "1. 基本网络，包括unet，vit，以及diffusion基本框架，还有各种normalize的操作\n",
    "2. 常用的损失函数和评价指标的计算\n",
    "3. python中基本的数据结构和lambda函数以及各种基本操作，还有numpy的基本操作以及绘图\n",
    "4. 模型训练的框架，和数据集的构造等\n",
    "5. 完成一些题目"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## python中的基本操作，包括lambda函数，数据结构以及numpy和绘图等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "8\n",
      "[1, 4, 9, 16]\n",
      "torch.Size([1, 4, 8, 16384])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "lambda 函数和各种操作\n",
    "语法: \n",
    "    lambda 参数1, 参数2, ... : 表达式\n",
    "\"\"\"\n",
    "from einops import rearrange\n",
    "import torch\n",
    "# 定义一个print函数和add函数\n",
    "pri = lambda x: print(x)\n",
    "pri(1)\n",
    "add = lambda x,y : x + y\n",
    "pri(add(3,5)) # 8\n",
    "\n",
    "\"\"\"\n",
    "将map函数和lambda函数结合\n",
    "map(function, iterable, ...)\n",
    "param:\n",
    "    function ：要应用到每个元素上的函数。 \n",
    "    iterable ：一个或多个可迭代对象（如列表、元组等）\n",
    "\"\"\"\n",
    "# 对列表中每个元素进行平方和\n",
    "numbers = [1,2,3,4]\n",
    "results = list(map(lambda t: t**2,numbers))\n",
    "pri(results)\n",
    "\n",
    "# 将qkv花开成q,k,v\n",
    "heads = 4\n",
    "dim_heads = 8\n",
    "# to_qkv 将输入的 x 变成 heads * dim_heads * 3\n",
    "qkv = torch.randn(1,96,128,128)\n",
    "qkv = qkv.chunk(3,dim=1) # 结果是一个包含 3 个张量的元组，每个张量的形状为 (1, 32, 128, 128) 。 分别对应 Query、Key、Value 。\n",
    "q,k,v = map(lambda t: rearrange(t,'b (h c) x y -> b h c (x y)',h = heads),qkv)\n",
    "pri(q.shape) # torch.Size([1, 4, 8, 16384])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "[2 3]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "numpy常用操作\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import torch\n",
    "# 创建数组\n",
    "a = np.array([1,2,3])\n",
    "b = np.zeros((3,3)) # torch.zeros(3,3)\n",
    "c = np.ones((3,3))\n",
    "d = np.full((3,3),5) # 填充指定的值\n",
    "e = np.random.rand(3,3) # 0,1之间的随机数 == torch.rand(3,3)\n",
    "f = torch.randn(3,3) # 标准正态分布的随机数\n",
    "g = np.arange(0,10,2) # 输出: array([0, 2, 4, 6, 8])\n",
    "h = np.linspace(0,1,5) # 输出: array([0.  , 0.25, 0.5 , 0.75, 1.  ])\n",
    "\n",
    "# 常用属性\n",
    "a.shape    # 数组形状\n",
    "a.dtype    # 数据类型\n",
    "a.size     # 元素总数\n",
    "a.ndim     # 数组维度\n",
    "\n",
    "# 形状操作\n",
    "a = np.array([[1,2,3],[4,5,6]])\n",
    "b = np.random.randn(4,3)\n",
    "a = a.reshape((3,2))\n",
    "a = a.T\n",
    "c = np.concatenate([a,b],axis = 0)\n",
    "\n",
    "# 随机种子\n",
    "np.random.seed(42)\n",
    "\n",
    "# 标准化\n",
    "data = np.random.randn(100,3)\n",
    "mean = np.mean(data,axis=0)\n",
    "std = np.var(data,axis=0)\n",
    "normalized_data = (data - mean) / std\n",
    "\n",
    "# 点积\n",
    "a = np.array([1, 2, 3])\n",
    "b = np.array([4, 5, 6])\n",
    "result = np.sum(a * b)  # sum([4 10 18])\n",
    "\n",
    "# 矩阵乘法\n",
    "print(np.dot(a,b.T))\n",
    "\n",
    "# 条件操作\n",
    "a = np.array([1,2,3])\n",
    "mask = a > 1\n",
    "print(a[mask])\n",
    "\n",
    "# TODO\n",
    "\"\"\"深拷贝，浅拷贝，轴操作（cat，sum，mean）等，以及和tensor的转换\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 绘图\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "lambda1 = np.array([1,10,100,1000])\n",
    "intra_psnr = [12.94, 12.9762, 13.0085, 13.2138]\n",
    "cross_psnr = [15.44, 15.4675, 15.5486, 15.5826]\n",
    "\n",
    "plt.figure(figsize = (10,6), dpi = 100)\n",
    "plt.grid(True,linestyle = '-', alpha = 0.7)\n",
    "\n",
    "intra_line, = plt.plot(lambda1,intra_psnr,\n",
    "                       marker = 'o',\n",
    "                       color = 'red',\n",
    "                       linewidth = 2,\n",
    "                       markersize = 8,\n",
    "                       label = 'Intra')\n",
    "cross_line, = plt.plot(lambda1,cross_psnr,\n",
    "                       marker = 's',\n",
    "                       color = 'blue',                       \n",
    "                       linewidth = 2,\n",
    "                       markersize = 8,\n",
    "                       label = 'Cross')\n",
    "\n",
    "intra_minIndex = np.argmin(intra_psnr)\n",
    "cross_minIndex = np.argmin(cross_psnr)\n",
    "\n",
    "plt.annotate(f'Intra min:{intra_psnr[intra_minIndex]}',\n",
    "             xy = (lambda1[intra_minIndex], intra_psnr[intra_minIndex]),\n",
    "             xytext=(lambda1[intra_minIndex] * 1.2,intra_psnr[intra_minIndex] - 0.1),\n",
    "             arrowprops=dict(arrowstyle = '->',color = 'red'),\n",
    "             fontsize = 10,\n",
    "             color = 'red'\n",
    ")\n",
    "plt.annotate(f'Cross min:{cross_psnr[cross_minIndex]}',\n",
    "             xy = (lambda1[cross_minIndex],cross_psnr[cross_minIndex]),\n",
    "             xytext=(lambda1[cross_minIndex] * 1.2, cross_psnr[cross_minIndex] - 0.1),\n",
    "             arrowprops=dict(arrowstyle = '->',color = 'blue'),\n",
    "             fontsize = 10,\n",
    "             color = 'blue'\n",
    "\n",
    ")\n",
    "\n",
    "plt.title('performance',fontsize = 20,pad = 20)\n",
    "plt.xlabel('lambda1',fontsize = 20)\n",
    "plt.xscale('log')\n",
    "plt.xticks(lambda1,labels=['1','10','100','1000'],fontsize = 20)\n",
    "plt.yticks(fontsize = 20)\n",
    "\n",
    "plt.legend(fontsize = 20,loc = 'center right',framealpha = 0.9)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 各种经典模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unet-attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Unet-attn\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from functools import partial\n",
    "# 必要的辅助函数\n",
    "def exists(val):\n",
    "    return val is not None\n",
    "\n",
    "def default(val,d):\n",
    "    return val if exists(val) else d\n",
    "\n",
    "def is_power_two(n):\n",
    "    return math.log2(n).is_integer()\n",
    "\n",
    "def divisible_by(num, denom):\n",
    "    return (num % denom) == 0\n",
    "\n",
    "def cast_tuple(val, length = None): \n",
    "    # 将val转换成元组, python中的列表是可变的, 而元组是不可变的\n",
    "    if isinstance(val,list):\n",
    "        val = tuple(val)\n",
    "    output = val if isinstance(val,tuple) else ((val,) * default(length,1))\n",
    "\n",
    "    if exists(length):\n",
    "        assert len(output) == length\n",
    "    return output\n",
    "\n",
    "\n",
    "\"\"\"上采样和下采样的函数\"\"\"\n",
    "\n",
    "# 1. pixelshuffle 和 pixelUnshuffle 实现上下采样\n",
    "\"\"\"\n",
    "H_in\n",
    "H_out = (H_in + 2*p - k)/s + 1\n",
    "\"\"\"\n",
    "class psUpsample(nn.Moudule):\n",
    "    def __init__(self,n_feats):\n",
    "        super(psUpsample,self).__init__()\n",
    "        \n",
    "        self.body = nn.Sequential(\n",
    "            nn.Conv2d(n_feats,n_feats * 4,kernel_size=3,stride=1,padding=1),\n",
    "            nn.PixelShuffle(2),\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        return self.body(x)\n",
    "\n",
    "class psDownsample(nn.Module):\n",
    "    def __init__(self, n_feats):\n",
    "        super(psDownsample,self).__init__()\n",
    "\n",
    "        self.body = nn.Sequential(\n",
    "            nn.Conv2d(n_feats, n_feats//4,kernel_size=3,stride=1,padding=1),\n",
    "            nn.PixelUnshuffle(2)\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        return self.body(x)\n",
    "\n",
    "# 2. 卷积实现上采样和下采样\n",
    "class Upsample(nn.Module):\n",
    "    def __init__(self,n_feats,feats_out):\n",
    "        super(Upsample,self).__init__()\n",
    "        self.body = nn.ConvTranspose2d(n_feats,feats_out,kernel_size=4,stride=2,padding=1)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        return self.body(x)\n",
    "\n",
    "class Downsample(nn.Module):\n",
    "    def __init__(self,n_feats,feats_out):\n",
    "        super(Downsample,self).__init__()\n",
    "\n",
    "        self.body = nn.Conv2d(n_feats,feats_out,kernel_size=4,stride=2,padding=1)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        return self.body(x)\n",
    "\n",
    "# 3. F.interpolate 实现上采样和下采样\n",
    "def downsample(x,scale_factor = 0.5):\n",
    "    return F.interpolate(x,scale_factor=scale_factor,mode='bilinear')\n",
    "def upsample(x,scale_factor = 2):\n",
    "    return F.interpolate(x, scale_factor=scale_factor,mode='bilinear')\n",
    "\n",
    "\"\"\"\n",
    "各种不同的 normalization 方法\n",
    "\"\"\"\n",
    "\n",
    "# 1. F.normalize\n",
    "\"\"\"\n",
    "normalize(x) = x / ||x||_2\n",
    "dim 控制沿着哪个维度计算均值\n",
    "\"\"\"\n",
    "def F_normalize(x,dim):\n",
    "    dim = default(dim,1)\n",
    "    return F.normalize(x,dim=dim)\n",
    "\n",
    "# 2. RMSNorm: 只对输入进行标准化，不减去均值, 归一化后数据在[-1,1]\n",
    "# 只缩放而不中心化\n",
    "\"\"\"\n",
    "RMSNorm(x) = x / (||x + \\epsilon||_2) * scale * gamma\n",
    "           = F.normalize(x, dim = 1) * scale * gamma\n",
    "param:\n",
    "    scale: 缩放因子, 是输入维度的平方根, 用于平衡不同维度的输出\n",
    "    gamma: 可学习的缩放参数, 用于调整归一化后的值, 形状和输入张量的dim维度相同(dim,1,1,1)\n",
    "           不仅可以标准化输入, 还可以动态调整数据分布\n",
    "    假设输入张量 x 的形状为 (2, 3, 4, 4) ,gamma 的形状为  (3, 1, 1) 。\n",
    "    在广播过程中： \n",
    "            gamma 会在 height 和 width 维度上扩展为 (3, 4, 4) 。\n",
    "            最终， gamma 的形状与 x 的形状一致，可以进行逐元素相乘。\n",
    "\"\"\"\n",
    "class RMSNorm(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.scale = dim ** 0.5\n",
    "        self.gamma = nn.Parameter(torch.ones(dim,1,1))\n",
    "    def forward(self,x):\n",
    "        return F.normalize(x,dim = 1) * self.scale * self.gamma\n",
    "    \n",
    "    \n",
    "# 3. LayerNorm: 对输入进行标准化，并减去均值, 归一化后均值为0，方差为1\n",
    "\"\"\"\n",
    "Layernorm(x) =  ( (x - mean(x)) / (var(x) + eps) ) * gamma\n",
    "\"\"\"\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.gamma = nn.Parameter(torch.ones(1,dim,1,1))\n",
    "    def forward(self,x):\n",
    "        eps = 1e-5 if x.dtype == torch.float32 else 1e-3\n",
    "        var = torch.var(x,dim= 1,unbiased=False,keepdim=True) # keepdim 方便后续逐元素进行广播操作\n",
    "        mean = torch.mean(x,dim = 1,keepdim=True)\n",
    "        return (x - mean) / (var + eps).sqrt() * self.gamma\n",
    "\n",
    "\n",
    "# 4. BatchNorm\n",
    "\"\"\"\n",
    "nn.BatchNorm2d(dim): 和layernorm不同, batchnorm沿着批次维度计算均值和方差\n",
    "\"\"\"\n",
    "\n",
    "# 5. batchnorm和layernorm的区别\n",
    "\"\"\"\n",
    "BatchNorm ： 依赖于 batch size。如果 batch size 太小，计算的均值和方差可能不准确，导致训练不稳定。 \n",
    "            在推理阶段，使用训练过程中累积的均值和方差（ running_mean 和 running_var ）。\n",
    "LayerNorm ： 不依赖于 batch size，对每个样本独立计算均值和方差。 \n",
    "            在训练和推理阶段的行为一致，无需累积统计量。\n",
    "            nlp任务中batch较小而且可能变化较大,所以用layernorm\n",
    "            对batchsize不敏感, 适合序列数据\n",
    "总结, batch > 32的时候用batchnorm, groupnorm适合小批量的图像数据(对channel分组做归一化), rmsnorm适合自回归模型(去中心化,计算量更少), layernorm适合序列数据\n",
    "\"\"\"\n",
    "# 权重标准化卷积\n",
    "class WeightStandardizedConv2d(nn.Conv2d):\n",
    "    \"\"\"\n",
    "        相较于传统的2d卷积, 这里对权重进行标准化操作, 标准化后缓解梯度爆炸/消失的问题\n",
    "    \"\"\"\n",
    "    def forward(self, x):\n",
    "        eps = 1e-5 if x.dtype == torch.float32 else 1e-3\n",
    "\n",
    "        weight = self.weight\n",
    "\n",
    "        mean = reduce(weight,'o ... -> o 1 1 1','mean')\n",
    "\n",
    "        var = reduce(weight,\"o ...->o 1 1 1\",partial(torch.var,unbiased = 'False'))\n",
    "        # partial(原函数, 参数1=值1, 参数2=值2...) 会生成一个新函数，调用这个新函数时，会自动带上你预设的参数。\n",
    "\n",
    "        weight = (weight - mean) * (var + eps).rsqrt()\n",
    "        return F.conv2d(x,weight,self.bias,self.stride,self.padding,self.dilation,self.groups)\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"定义构建模块\"\"\"\n",
    "class Residual(nn.Module):\n",
    "    def __init__(self, fn):\n",
    "        super().__init__()\n",
    "        self.fn = fn\n",
    "    def forward(self,x):\n",
    "        return self.fn(x) + x\n",
    "    \n",
    "class Block(nn.Module):\n",
    "    def __init__(self, \n",
    "                 dim,\n",
    "                 dim_out,\n",
    "                 groups = 8,\n",
    "                 weight_standardize = False):\n",
    "        super().__init__()\n",
    "        conv = nn.Conv2d if not weight_standardize else WeightStandardizedConv2d\n",
    "\n",
    "        self.proj = conv(dim,dim_out,kernel_size=3,padding=1,stride=1)\n",
    "        #self.norm = RMSNorm(dim_out)\n",
    "        self.norm = nn.GroupNorm(groups,dim_out)\n",
    "        self.act = nn.SiLU()\n",
    "        # silu = x · sigmoid(x) 更平滑相较于relu, 缓解梯度消失和爆炸\n",
    "    def forward(self,x):\n",
    "        x = self.proj(x)\n",
    "        x = self.norm(x)\n",
    "        return self.act(x)\n",
    "\n",
    "class ResnetBlock(nn.Module):\n",
    "    def __init__(self,\n",
    "                 dim,\n",
    "                 dim_out,\n",
    "                 groups = 8,\n",
    "                 weight_standardize = True):\n",
    "        super().__init__()\n",
    "        self.block1 = Block(dim,dim_out,groups=groups,weight_standardize=weight_standardize)\n",
    "        self.block2 = Block(dim_out,dim_out,groups,weight_standardize)\n",
    "        \n",
    "        self.res_conv = nn.Conv2d(dim,dim_out,1) if dim != dim_out else nn.Identity()\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "\n",
    "        return self.res_conv(x) + x\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, \n",
    "                 dim,\n",
    "                 heads = 4,\n",
    "                 dim_heads = 32):\n",
    "        super().__init__()\n",
    "        self.scale = dim_heads ** -0.5\n",
    "        self.heads = heads\n",
    "        hidden_dim = self.heads * dim_heads\n",
    "\n",
    "        self.to_qkv = nn.Conv2d(dim,hidden_dim * 3,1)\n",
    "        self.to_out = nn.Conv2d(hidden_dim,dim,1)\n",
    "    def forward(self,x):\n",
    "        b,c,h,w = x.shape\n",
    "\n",
    "        qkv = self.to_qkv(x).chunk(3,dim =1)\n",
    "        # 变成一个有三个元素的元组\n",
    "        q,k,v = map(lambda t: rearrange('b (h dh) h w -> b h dh (h w)',h = self.heads),qkv)\n",
    "\n",
    "        q  = q*self.scale\n",
    "\n",
    "        sim = einsum('b h d i,b h d j -> b h i j',q,k)\n",
    "        attn = sim.softmax(dim = -1) # 这里得到的是i中每个点与j中所有元素的相关性，softmax做了概率归一化\n",
    "        out = einsum('b h i j, b h d j -> b h i d',attn,v)\n",
    "        # 最终out 中d个维度上的每个像素点都是其他所有位置的加权求和, attn是为了得到这个权重\n",
    "        out = rearrange(out,'b h (x y) d -> b (h d) x y',x = h,y = w)\n",
    "\n",
    "        return self.to_out(out)\n",
    "\n",
    "class LinearAttention(nn.Module):\n",
    "    def __init__(self, \n",
    "                 dim,\n",
    "                 heads,\n",
    "                 dim_heads):\n",
    "        super().__init__()\n",
    "        self.scale = dim_heads ** -0.5\n",
    "        self.heads = heads\n",
    "        hidden_dim = heads * dim_heads\n",
    "\n",
    "        self.to_qkv = nn.Conv2d(dim,hidden_dim * 3,1)\n",
    "        self.to_out = nn.Sequential(\n",
    "            nn.Conv2d(hidden_dim,dim,1),\n",
    "            LayerNorm(dim)\n",
    "        )\n",
    "        \"\"\"\n",
    "        标准注意力 ：精确的全局交互（通过 softmax(QK^T)V ）天然具有归一化效果。 \n",
    "        线性注意力 ：近似计算（如核方法或分解）可能导致输出分布偏移， LayerNorm 用于校准特征尺度。\n",
    "        \"\"\"\n",
    "    def forward(self,x):\n",
    "        b,c,h,w = x.shape\n",
    "\n",
    "        qkv = self.to_qkv(x).chunk(3,dim = 1)\n",
    "        q,k,v = map(lambda t:rearrange(t, 'b (h dh) x y -> b h dh (x y)',h = heads),qkv)\n",
    "\n",
    "        q = q.softmax(dim = -2)\n",
    "        k = k.softmax(dim = -1)\n",
    "\n",
    "        q = self.scale * q\n",
    "        v = v / (h * w)\n",
    "\n",
    "        context = einsum('b h d n, b h e n -> b h d e',k,v) # 得到d*d 对(xy) * (xy)作低秩近似\n",
    "\n",
    "        out = einsum('b h d e, b h d n -> b h e n',context,q) # d * d 和 d * hw在倒数第二个维度上求和, 得到 d * hw\n",
    "        out = rearrange(out, 'b h d (x y) -> b (h d) x y',x = h,y = w)\n",
    "        return self.to_out(out)\n",
    "class Prenorm(nn.Module):\n",
    "    def __init__(self, dim,fn):\n",
    "        super().__init__()\n",
    "        self.fn = fn\n",
    "        self.norm = LayerNorm(dim)\n",
    "    def forward(self,x):\n",
    "        x = self.norm(x)\n",
    "        return self.fn(x)\n",
    "\n",
    "\n",
    "\"\"\"定义Unet模型\"\"\"\n",
    "class Unet(nn.Module):\n",
    "    def __init__(self, \n",
    "                 dim,\n",
    "                 init_dim,\n",
    "                 dim_out,\n",
    "                 dim_mults = (1,2,4,8),\n",
    "                 channels = 31,\n",
    "                 condition_channel=10,\n",
    "                 resnet_block_groups = 8,# 主要用于resnet里的groupnorm把dim分成几组作归一化\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        self.channels = channels\n",
    "        input_channels = channels + condition_channel\n",
    "\n",
    "        init_dim = default(init_dim,dim)\n",
    "        self.init_conv = nn.Conv2d(input_channels,init_dim,7,padding=3)\n",
    "\n",
    "        dims = [init_dim, *map(lambda t: dim * t, dim_mults)]\n",
    "        in_out = list(zip(dims[:-1]),dims[1:])\n",
    "        # (dim_in, dim_out)按组来\n",
    "\n",
    "        block_klass = partial(ResnetBlock, groups = resnet_block_groups)\n",
    "\n",
    "        self.downs = nn.ModuleList([]) # module list里的一个元素就是相当于sequential\n",
    "        self.ups = nn.ModuleList([])\n",
    "\n",
    "        num_resolutions = len(in_out)\n",
    "\n",
    "        for ind,(dim_in,dim_out) in enumerate(in_out):\n",
    "            is_last = ind >=(num_resolutions - 1)\n",
    "            self.downs.append([\n",
    "                block_klass(dim_in,dim_in),\n",
    "                block_klass(dim_in,dim_in),\n",
    "                Residual(Prenorm(dim_in,LinearAttention(dim_in))),\n",
    "                Downsample(dim_in,dim_out) if not is_last else nn.Conv2d(dim_in,dim_out,3,padding=1)\n",
    "            ])\n",
    "\n",
    "        mid_dim = dims[-1]\n",
    "        self.mid_blocks1 = block_klass(mid_dim,mid_dim)\n",
    "        self.mid_attn = Residual(Prenorm(mid_dim,Attention(mid_dim)))\n",
    "        self.mid_blocks2 = block_klass(mid_dim,mid_dim)\n",
    "\n",
    "        for ind,(dim_in,dim_out) in enumerate(reversed(dims)):\n",
    "            is_last = ind == (len(in_out) - 1)\n",
    "            self.ups.append(nn.ModuleList([\n",
    "                block_klass(dim_in + dim_out,dim_out),\n",
    "                block_klass(dim_in + dim_out,dim_out),\n",
    "                Residual(Prenorm(dim_out,LinearAttention(dim_out))),\n",
    "                Upsample(dim_out,dim_in) if not is_last else nn.Conv2d(dim_out, dim_in, 3, padding=1)\n",
    "            ]))\n",
    "        self.out_dim = default(dim_out,channels)\n",
    "        self.final_res_block = block_klass(dim * 2,dim)\n",
    "        self.final_conv = nn.Conv2d(dim,self.out_dim,1)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.init_conv(x)\n",
    "\n",
    "        r = x.clone\n",
    "        h = []\n",
    "\n",
    "        for block1,block2,attn,downs in self.downs:\n",
    "            x = block1(x)\n",
    "            h.append(x)\n",
    "\n",
    "            x = block2(x)\n",
    "            x = attn(x)\n",
    "            h.append(x)\n",
    "\n",
    "            x = downs(x)\n",
    "        \n",
    "        x = self.mid_blocks1(x)\n",
    "        x = self.mid_attn(x)\n",
    "        x = self.mid_blocks2(x)\n",
    "\n",
    "        for block1, block2, attn, ups in self.ups:\n",
    "            x = torch.cat([x,h.pop()],dim = 1)\n",
    "            x = block1(x)\n",
    "\n",
    "            x = torch.cat([x,h.pop()],dim=1)\n",
    "            x = block2(x)\n",
    "            x = attn(x)\n",
    "\n",
    "            x = ups(x)\n",
    "        \n",
    "        x = torch.cat([x,r], dim = 1)\n",
    "        x = self.final_res_block(x)\n",
    "\n",
    "        return self.final_conv(x)\n",
    "\n",
    "\n",
    "# 除了框架上的内容还有各种损失函数,优化器。。。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义构建vit模型\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from einops import repeat,rearrange,reduce\n",
    "from einops.layers.torch import Rearrange\n",
    "\n",
    "def pair(t):\n",
    "    return t if isinstance(t,tuple) else (t,t)\n",
    "# 这个函数通常用于需要将单个值转换为元组的场景，尤其是在需要确保处理的对象是元组的情况下。\n",
    "# 例如，在某些库或框架中，可能需要将单个值扩展为元组以保持一致性。\n",
    "# result = pair(3) : (3,3)\n",
    "\n",
    "# classes\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, dim,mlp_dim,dropout = 0.):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.LayerNorm(dim),\n",
    "            nn.Linear(dim,mlp_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(mlp_dim,dim),\n",
    "            nn.GELU\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        return self.net(x)\n",
    "# 先norm再attention,同理先norm再ffn\n",
    "# GELU 在自然语言处理和计算机视觉任务中通常优于 ReLU 和 SiLU\n",
    "# silu是gelu的近似版本，计算更简单，性能接近gelu\n",
    "# gelu = x · \\phi(x),phi是标准正态分布的累积分布函数\n",
    "\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, dim,heads = 4, dim_heads = 32, dropout = 0.):\n",
    "        super().__init__()\n",
    "\n",
    "        self.heads = heads\n",
    "        hidden_dim = heads * dim_heads\n",
    "        project_out = not (heads == 1 and dim == hidden_dim)\n",
    "\n",
    "        self.scale = dim_heads ** -0.5\n",
    "        self.norm = LayerNorm(dim)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.to_qkv = nn.Linear(dim, hidden_dim * 3)\n",
    "        self.to_out = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, dim),\n",
    "            nn.Dropout(dropout),\n",
    "        )if project_out else nn.Identity()\n",
    "    def forward(self,x):\n",
    "        x = self.norm(x)\n",
    "\n",
    "        qkv = self.to_qkv(x).chunk(3,dim = -1)\n",
    "        q,k,v = map(lambda t: rearrange(t,'b n (h d)-> b h n d',h = self.heads),qkv)\n",
    "        q = q * self.scale\n",
    "\n",
    "        attn = einsum('b h n d, b h e d -> b h n e',q,k)\n",
    "        attn = attn.softmax(dim = -1)\n",
    "        attn = self.dropout(attn)\n",
    "\n",
    "        out = einsum('b h n e, b h e d -> b h n d',attn, v)\n",
    "        out = rearrange(out,'b h n d -> b n (h d)')\n",
    "\n",
    "        return self.to_out(out)\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, dim, depth, heads, dim_heads, mlp_dim, dropout = 0.):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        self.layers = nn.ModuleList([])\n",
    "        for _ in range(depth):\n",
    "            self.layers.append(nn.ModuleList([\n",
    "                Attention(dim,heads,dim_heads,dropout),\n",
    "                FeedForward(dim,mlp_dim,dropout)\n",
    "            ]))\n",
    "    def forward(self,x):\n",
    "        for attn,ff in self.layers:\n",
    "            x = attn(x) + x\n",
    "            x = ff(x) + x\n",
    "        return self.norm(x) \n",
    "    \n",
    "class ViT(nn.Module):\n",
    "    def __init__(self, image_size,patch_size,num_classes,dim,depth,heads,mlp_dim,pool = 'cls',dim_heads = 64,channels = 3,dropout = 0.):\n",
    "        super().__init__()\n",
    "        \"\"\"\n",
    "        dim: 是把展平后的patch看成通道维度，并压缩到dim\n",
    "        num_classes: 最后要输出的图像类别数目，vit最早是用来做图像分类任务的\n",
    "        \"\"\"\n",
    "        image_height,image_width = pair(image_size)\n",
    "        patch_height,patch_width = pair(patch_size)\n",
    "\n",
    "        assert image_size % patch_size == 0\n",
    "\n",
    "        num_patches = (image_height//patch_height) * (image_width // patch_width)\n",
    "\n",
    "        patch_dim = channels * patch_width * patch_height \n",
    "        # 把一个patch里的所有像素展平 作为dim\n",
    "        assert pool in {'cls','mean'},'pool type must be either cls (cls token) or mean (mean pooling)'\n",
    "        # 在 forward 方法中， pool = 'cls' 时，直接取 Transformer 输出的第一个位置（即 CLS Token 对应的输出）作为特征\n",
    "        # 在 pool = 'mean' 时，对 Transformer 输出的所有位置（包括 CLS Token 和 patch embeddings）进行全局平均池化\n",
    "        self.to_patch_embedding = nn.Sequential(\n",
    "            Rearrange('b c (h p1) (w p2)-> b (h w) (p1 p2 c)',p1 = patch_height,p2 = patch_width),\n",
    "            nn.LayerNorm(patch_dim),\n",
    "            nn.Linear(patch_dim,dim),\n",
    "            nn.LayerNorm(dim)\n",
    "        )\n",
    "        self.pos_embedding = nn.parameter(torch.randn(1, num_patches + 1,dim)) \n",
    "        # 为每个像素加上位置信息, num_patches 要加一是因为 除了num个patch以外, vit还设计了一个token存储全局信息\n",
    "        self.cls_token = nn.Parameter(torch.randn(1,1,dim))\n",
    "\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "\n",
    "        self.transformer = Transformer(dim,depth,heads,dim_heads,mlp_dim)\n",
    "\n",
    "        self.pool = pool\n",
    "        self.to_latent = nn.Identity()\n",
    "        self.mlp_head = nn.Linear(dim,num_classes)\n",
    "    \n",
    "    def forward(self,img):\n",
    "        x = self.to_patch_embedding(img)\n",
    "\n",
    "        b, n,_ = x.shape\n",
    "\n",
    "        cls_tokens = repeat(self.cls_token,'1 1 d -> b 1 d',b = b)\n",
    "        x = torch.cat([x, cls_tokens],dim = 1)\n",
    "        x += self.pos_embedding[:,:(n + 1)]\n",
    "        x = self.drop(x)\n",
    "\n",
    "        x = self.transformer(x)\n",
    "\n",
    "        x = x.mean(dim = 1) if self.pool == 'mean' else x[:,0]\n",
    "        x = self.to_latent(x)\n",
    "\n",
    "        return self.mlp_head(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 神经网络训练框架"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 张量基础\n",
    "- 张量操作: view reshape permute squeeze \n",
    "- 自动求导: requires_grad backward grad累积问题\n",
    "\n",
    "### 2. 神经网络\n",
    "- 损失函数crossentropy, mse\n",
    "- 优化器SGD,Adam,zero_grad()的必要性问题\n",
    "\n",
    "### 3. 数据训练\n",
    "- Dataset 与 DataLoader （自定义数据集、批处理、 collate_fn ） \n",
    "- 训练循环（ train() / eval() 模式、 with torch.no_grad() ） \n",
    "- 模型保存与加载（ state_dict 、跨设备加载）\n",
    "\n",
    "### 4. 大框架\n",
    "- 一套完整的训练流程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"张量基础\"\"\"\n",
    "# 1. view\n",
    "# 改变张量的形状 ，但不改变数据存储顺序 （即共享底层内存）。 \n",
    "# 要求张量在内存中是连续的 （contiguous），否则会报错。\n",
    "x = torch.arange(6)\n",
    "y = x.view(2,3)\n",
    "y[0,0] = 100 # 修改 y 会影响 x, 因为共享内存\n",
    "# ps: 如果张量不连续, 比如经过了transpose和permute的操作后, 必须先调用contiguous()后再调用view()\n",
    "x = torch.randn(2,3).transpose(0,1)\n",
    "y = x.contiguous().view(6)\n",
    "\n",
    "\n",
    "\n",
    "# 2. reshape\n",
    "# 功能与 view() 类似，但 自动处理连续性 ：\n",
    "#   如果张量连续，则和view一样共享内存\n",
    "#   如果张量不连续，则创建副本\n",
    "x = torch.randn(6).reshape(2,3)\n",
    "y = x.reshape(3,2) #  和 x 共享内存\n",
    "\n",
    "x = torch.randn(2,3).transpose(0,1)\n",
    "y = x.reshape(6) # 创建副本，修改 y 不影响 x\n",
    "\n",
    "\n",
    "\n",
    "# 3. permute() 维度重排列，相当于高阶转置，而transpose只能交换两个维度\n",
    "# x 和 y 共享内存\n",
    "x = torch.randn(2,3,4)\n",
    "y = x.permute(2,0,1) # (4,2,3)\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"自动求导\"\"\"\n",
    "# 1. requires_grad: 梯度追踪开关\n",
    "# 作用: 标记张量是否需要计算梯度\n",
    "# 叶子节点（直接创建的张量）的 requires_grad 需要显式设置 。\n",
    "x = torch.tensor([1.0],requires_grad=True)\n",
    "y = torch.tensor([2.0])\n",
    "z = x * y # 非叶子结点自动继承梯度, z.requires_grad → True\n",
    "\n",
    "# 2. backward(): 反向传播\n",
    "# 只能对标量张量调用, 默认释放计算图, 梯度存储在叶子结点的.grad属性里\n",
    "loss = z.sum()\n",
    "loss.backward()\n",
    "print(x.grad)\n",
    "\n",
    "# 3. grad:梯度存储, 梯度计算结果存储在叶子结点的.grad属性中\n",
    "# 默认梯度会累积, 除非手动清零\n",
    "# 梯度累积现象\n",
    "x = torch.tensor([3.0],requires_grad=True)\n",
    "optimizer = torch.optim.SGD([x],lr=0.01)\n",
    "y = x**2\n",
    "y.backward() # dy/dx = 2x = 6 → x.grad = 6\n",
    "optimizer.step() # x = 3 - 0.01 * 6 = 2.4\n",
    "# 第二次计算, 未清零梯度\n",
    "y = x**2\n",
    "y.backward() # dy/dy = 2x = 4.8 -> x.grad = 6 + 4.8\n",
    "optimizer.step() # x = 2.4 - 0.01 * 10.8\n",
    "optimizer.zero_grad() # !!! 每次step要调用.zero_grad()清零梯度\n",
    "# clone 会保存梯度追踪, 但新张量会变成非叶子结点\n",
    "xx = x.clone() # xx是非叶子节点，requires_grad=True\n",
    "yy = x.detach().clone() # detach可以断开计算图的计算\n",
    "\n",
    "# 如果设置retain_graph = true就可以两次backward()\n",
    "x = torch.tensor([2.0],requires_grad=True)\n",
    "y = x**2\n",
    "y.backward() # x.grad = 4\n",
    "y.backward() # x.grad = 4 + 4 = 8\n",
    "optimizer.step() # x = 2 - 8 * 0.01\n",
    "\n",
    "\n",
    "\n",
    "# 4. torch.auto.grad\n",
    "# grad_x , grad_y = torch.autograd.grad(outputs = loss, \n",
    "#                   nputs = [x,y], create_graph = False # 是否保留计算图（用于高阶导数）)\n",
    "x = torch.randn([2.0], requires_grad=True)\n",
    "y = torch.randn([3.0],requires_grad= True)\n",
    "z = x**2 + y**3\n",
    "# 计算梯度（仅返回结果，不修改x.grad/y.grad）\n",
    "x_grad,y_grad = torch.autograd.grad(\n",
    "    z,[x,y],create_graph = False # 不保留计算图\n",
    ")\n",
    "pri(x_grad) # dz/dx\n",
    "pri(y_grad) # dz/dy\n",
    "pri(x.grad) # None\n",
    "# 计算高阶导数\n",
    "x = torch.tensor([2.0],requires_grad=True)\n",
    "y = x**3\n",
    "dy_dx = torch.autograd.grad(\n",
    "    y,x,create_graph=True\n",
    ")[0]\n",
    "d2y_dx2 = torch.autograd.grad(dy_dx,x)[0] #  计算二阶导数\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Dataset and Dataloader\"\"\"\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "from pathlib import Path\n",
    "# 自定义数据集(Dataset), 定义数据加载逻辑, 文件读取,预处理等\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self,folder,transform = None,exts = ['jpg','png']):\n",
    "        super().__init__()\n",
    "        self.exts = exts\n",
    "        self.gt = self.load_flist(folder[0])\n",
    "        self.data = self.load_flist(folder[1])\n",
    "        self.trans = transform\n",
    "    def __len__(self):\n",
    "        return len(self.gt)\n",
    "    def __getitem__(self, index):\n",
    "        gt_image = Image.open(self.gt[index])\n",
    "        data = Image.open(self.data[index])\n",
    "        \n",
    "        if self.trans is not None:\n",
    "            return [self.trans(gt_image),self.trans(data)]\n",
    "        return [gt_image, data]\n",
    "    def load_flist(self, folder):\n",
    "        if isinstance(folder,list):\n",
    "            return list\n",
    "        if isinstance(folder,str):\n",
    "            if os.path.isdir(folder):\n",
    "                return [p for ext in self.exts for p in Path(f'{folder}').glob(f'**/*.{ext}')]\n",
    "\n",
    "dataset = MyDataset('')\n",
    "dataloader = DataLoader(\n",
    "    dataset=dataset,\n",
    "    batch_size= 4,\n",
    "    shuffle=True,\n",
    ")\n",
    "for batch_data, batch_loader in dataloader:\n",
    "    pass\n",
    "\n",
    "# Trainer\n",
    "class Trainer(object):\n",
    "    def __init__(self,\n",
    "                 model,\n",
    "                 folder,\n",
    "                 training_lr,\n",
    "                 opt\n",
    "                 # batch_size等等, 可以存放在opt里\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        \n",
    "        self.save_step = opt.save_step\n",
    "        self.test_step = opt.test_step\n",
    "\n",
    "        ds_train = MyDataset(folder[:2])\n",
    "        ds_test = MyDataset(folder[2:4])\n",
    "\n",
    "        self.dl_train = DataLoader(ds_train,opt.batch_size,shuffle=True)\n",
    "        self.dl_test = DataLoader(ds_test,opt.batch_size,shuffle=False)\n",
    "        \n",
    "        self.optim = torch.optim.Adam(self.model,training_lr,weight_decay=opt.weight_decay)\n",
    "        # weight_decay: 正则化技术, 对原有的损失项加上 \\lambda||w||_2的约束, 让部分的参数为0, 约束模型复杂度\n",
    "        self.device = opt.device\n",
    "        self.model.to(self.device)\n",
    "        self.save_path = opt.save_path\n",
    "        self.log_path = opt.log_path\n",
    "        os.makedirs(self.save_path,exist_ok=True)\n",
    "\n",
    "        self.lossf = nn.L1Loss()\n",
    "    def save(self, epoch):\n",
    "        save_path = self.save_path\n",
    "        torch.save(\n",
    "            {\n",
    "                'epoch':epoch,\n",
    "                'model_state_dict':self.model.state_dict(),\n",
    "                'optimizer_state_dict':self.optim.state_dict()\n",
    "            },\n",
    "            save_path\n",
    "        )\n",
    "        print(f'Epoch:{epoch},model saved to {save_path}')\n",
    "\n",
    "    def load(self,checkpoint_path):\n",
    "        checkpoint = torch.load(checkpoint_path,map_location=self.device)\n",
    "\n",
    "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        self.optim.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        print(f'model loaded from {checkpoint_path}')\n",
    "        return checkpoint['epoch']\n",
    "    def train(self,num_epochs,start_epochs):\n",
    "        for epoch in range(start_epochs,num_epochs):\n",
    "            self.model.train()\n",
    "            running_loss = 0\n",
    "\n",
    "            for batch_data, batch_gt in self.dl_train:\n",
    "                batch_data = batch_data.to(self.device)\n",
    "                batch_gt = batch_gt.to(self.device)\n",
    "\n",
    "                outputs = self.model(batch_data)\n",
    "                loss = self.lossf(outputs,batch_gt)\n",
    "\n",
    "                self.optim.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optim.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "            print(f'{epoch + 1}/{num_epochs},loss:{running_loss / len(self.dl_train)}')\n",
    "            if epoch % self.save_step:\n",
    "                self.save(epoch + 1)\n",
    "            if epoch % self.test_step:\n",
    "                self.test()\n",
    "    def test(self):\n",
    "        self.model.eval()\n",
    "        loss_total = 0\n",
    "        \"\"\"这里还可以计算指标等操作\"\"\"\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_data, batch_gt in self.dl_test:\n",
    "                batch_data = batch_data.to(self.device)\n",
    "                batch_gt = batch_gt.to(self.device)\n",
    "\n",
    "                output = self.model(batch_data)\n",
    "\n",
    "                loss = self.lossf(output,batch_gt)\n",
    "\n",
    "                loss_total += loss.item()\n",
    "        with open(self.log_path,'a') as file:\n",
    "            file.write(f'')\n",
    "        print(\" \")\n",
    "# 使用parser解析命令行参数\n",
    "import argparse\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(description='TrainerConfig')\n",
    "\n",
    "    parser.add_argument('--...',type = str,default=None,help='')\n",
    "    parser.add_argument('--resume',str,default=None,help='path to checkpoint to resume training')\n",
    "\n",
    "    return parser.parse_args()\n",
    "\n",
    "def main():\n",
    "    opt = parse_args()\n",
    "\n",
    "    model = \"\"\n",
    "\n",
    "    trainer = Trainer()\n",
    "\n",
    "    start_epoch = 0\n",
    "    if opt.resume:\n",
    "        start_epoch = trainer.load(opt.resume)\n",
    "    trainer.train(start_epoch)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n",
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
